{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gosiuniunia/uczenie-glebokie/blob/main/attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2446fdd",
      "metadata": {
        "id": "f2446fdd"
      },
      "source": [
        "Źródła:\n",
        "\n",
        "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
        "\n",
        "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
        "\n",
        "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023.\n",
        "\n",
        "SU, Jiawei; VARGAS, Danilo Vasconcellos; SAKURAI, Kouichi. One pixel attack for fooling deep neural networks. IEEE Transactions on Evolutionary Computation, 2019, 23.5: 828-841.\n",
        "\n",
        "WONG, Eric; RICE, Leslie; KOLTER, J. Zico. Fast is better than free: Revisiting adversarial training. arXiv preprint arXiv:2001.03994, 2020.\n",
        "\n",
        "MOOSAVI-DEZFOOLI, Seyed-Mohsen; FAWZI, Alhussein; FROSSARD, Pascal. Deepfool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. p. 2574-2582.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZLw7AZ3ekD88",
        "outputId": "88e11705-ee91-4b28-fe6a-39f4f4db0c6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZLw7AZ3ekD88",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchattacks\n",
        "!pip install sewar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmV4mnuJpq8A",
        "outputId": "e17c8ec5-1299-43e3-9830-52037a11dc3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hmV4mnuJpq8A",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (0.24.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.0.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.8.2->torchattacks) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.3)\n",
            "Requirement already satisfied: sewar in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sewar) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sewar) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sewar) (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8708bca8",
      "metadata": {
        "id": "8708bca8",
        "outputId": "05072788-1625-4638-c8fe-afe6a52b48bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f80f6d4e4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import sewar\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
        "\n",
        "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
        "from torchattacks import PGD, FGSM, CW, AutoAttack, DeepFool, OnePixel\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3a884b19",
      "metadata": {
        "id": "3a884b19",
        "outputId": "c6f8fa6c-af26-488f-f0fc-4936fb0ff37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG and ResNet architecture"
      ],
      "metadata": {
        "id": "-l7ze4nMRrg5"
      },
      "id": "-l7ze4nMRrg5"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc0597d1",
      "metadata": {
        "collapsed": true,
        "id": "dc0597d1"
      },
      "outputs": [],
      "source": [
        "# VGG model architecture\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Blok 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256*4*4, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        # x = self.block5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b11b9050",
      "metadata": {
        "collapsed": true,
        "id": "b11b9050"
      },
      "outputs": [],
      "source": [
        "# ResNet18 model architecture\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main_path = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                      stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main_path(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
        "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
        "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
        "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack generation function"
      ],
      "metadata": {
        "id": "60GuQ88oRz2G"
      },
      "id": "60GuQ88oRz2G"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_images(source_model, dataset, mean, std, source_name, train=False, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generates adversarial images for all attacks in batches to avoid CUDA OOM.\n",
        "    \"\"\"\n",
        "    attack_configs = [\n",
        "        {\"name\": \"FGSM\", \"atk\": FGSM(source_model, eps=4/255)},\n",
        "        {\"name\": \"PGD\", \"atk\": PGD(source_model, eps=4/255, alpha=2/255, steps=20, random_start=True)},\n",
        "        {\"name\": \"CW\", \"atk\": CW(source_model, c=1, steps=300, lr=0.01)},\n",
        "        {\"name\": \"AutoAttack\", \"atk\": AutoAttack(source_model, norm=\"Linf\", eps=4/255)},\n",
        "        {\"name\": \"DeepFool\", \"atk\": DeepFool(source_model, steps=50, overshoot=0.02)},\n",
        "        {\"name\": \"OnePixel\", \"atk\": OnePixel(source_model, pixels=1, steps=50, popsize=20)}\n",
        "    ]\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for config in attack_configs:\n",
        "        attack_name = config[\"name\"]\n",
        "        atk = config[\"atk\"]\n",
        "        print(f\"Generating {attack_name} attacks\")\n",
        "\n",
        "        if attack_name == \"AutoAttack\":\n",
        "            atk.attacks_to_run = ['apgd-ce']\n",
        "\n",
        "        atk.set_normalization_used(mean, std)\n",
        "        adv_images_list = []\n",
        "        adv_labels_list = []\n",
        "\n",
        "        for batch_images, batch_labels in loader:\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            adv_batch = atk(batch_images, batch_labels)\n",
        "\n",
        "            adv_images_list.append(adv_batch.cpu())\n",
        "            adv_labels_list.append(batch_labels.cpu())\n",
        "\n",
        "            del batch_images, batch_labels, adv_batch\n",
        "\n",
        "        adv_images_all = torch.cat(adv_images_list)\n",
        "        adv_labels_all = torch.cat(adv_labels_list)\n",
        "\n",
        "        folder_prefix = \"train\" if train else \"test\"\n",
        "        save_images(adv_images_all, adv_labels_all, adv_images_folder_path, f\"{folder_prefix}_{source_name}_{attack_name}\")\n"
      ],
      "metadata": {
        "id": "URG21dM3lQyK"
      },
      "id": "URG21dM3lQyK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial images saving and loading functions"
      ],
      "metadata": {
        "id": "lw050aiISDsV"
      },
      "id": "lw050aiISDsV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save images to the designated folder\n",
        "\n",
        "def save_images(images, labels, path, folder_name=None):\n",
        "  \"\"\"\n",
        "  This function saves given images with their labels in the given folder.\n",
        "  Subfolder can be specified. Each image is saved as adv_image_{index}_label_{labels[index]}.png,\n",
        "  \"\"\"\n",
        "  try:\n",
        "    path = os.path.join(path, folder_name)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  for i, (image_tensor, label) in enumerate(zip(images, labels)):\n",
        "    img = image_tensor.detach().permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).clip(0,255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(img)\n",
        "\n",
        "    filename = f\"adv_image_{i}_label_{int(label)}.png\"\n",
        "    filepath = os.path.join(path, filename)\n",
        "    image_pil.save(filepath)"
      ],
      "metadata": {
        "id": "jAlQUFmRudGS"
      },
      "id": "jAlQUFmRudGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all of the images in specified folder to torch dataset\n",
        "\n",
        "class AdversarialImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class loads the images from specified folder (save_images generated folder)\n",
        "    and transforms it to torch dataset for future learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".png\"):\n",
        "                self.image_files.append(file)\n",
        "\n",
        "        self.image_files.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        label = int(img_name.split(\"_\")[-1].split(\".\")[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "DZjOmzanJq9y"
      },
      "id": "DZjOmzanJq9y",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funtions for evaluation"
      ],
      "metadata": {
        "id": "TN41LZjJSJus"
      },
      "id": "TN41LZjJSJus"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, mean, std):\n",
        "  model.eval()\n",
        "\n",
        "  preds = []\n",
        "  labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      preds.append(model(X).argmax(1).cpu())\n",
        "      labels.append(y.cpu())\n",
        "\n",
        "  preds = torch.cat(preds)\n",
        "  labels = torch.cat(labels)\n",
        "\n",
        "  return preds, labels"
      ],
      "metadata": {
        "id": "hHPnNQuBW644"
      },
      "id": "hHPnNQuBW644",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c936e98a",
      "metadata": {
        "id": "c936e98a"
      },
      "outputs": [],
      "source": [
        "# Attack efficiency metrics\n",
        "\n",
        "def attack_success_rate(labels, preds):\n",
        "    \"\"\"\n",
        "    Computes the Attack Success Rate (ASR).\n",
        "    Measures how many attacks succeeded.\n",
        "    \"\"\"\n",
        "    labels, preds = labels.to(device), preds.to(device)\n",
        "    total = len(labels)\n",
        "    succeeded = (preds != labels).sum().item()\n",
        "    return 100.0 * succeeded / total\n",
        "\n",
        "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the fooling rate for transfer attacks.\n",
        "\n",
        "    - source_pred: predictions of the SOURCE model on adversarial images\n",
        "    - target_pred: predictions of the TARGET model on adversarial images\n",
        "    - clean_target_pred: predictions of the TARGET model on clean images\n",
        "\n",
        "    We measure cases where:\n",
        "    1) the adversarial sample fools the SOURCE model,\n",
        "    2) it also fools the TARGET model,\n",
        "    3) but the TARGET classified the clean version correctly.\n",
        "\n",
        "    The fooling rate is: Q / P\n",
        "    where:\n",
        "        P = number of samples that fooled the source\n",
        "        Q = number of samples that fooled both models\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    fool_source = source_pred != labels\n",
        "    fool_target = target_pred != labels\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "\n",
        "    P = fool_source.sum().item()\n",
        "    Q = (fool_source & fool_target & correct_target_clean).sum().item()\n",
        "\n",
        "    return 100.0 * Q / P if P > 0 else 0.0\n",
        "\n",
        "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the rate at which both the source and target models make\n",
        "    the SAME wrong prediction on adversarial samples.\n",
        "\n",
        "    We consider ONLY samples where:\n",
        "    - the target model classified the CLEAN image correctly\n",
        "    - the target model is fooled on the adversarial image\n",
        "\n",
        "    Among those, we measure how often:\n",
        "        source_pred == target_pred (same incorrect class)\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "    fool_target = target_pred != labels\n",
        "    same_mistake = source_pred == target_pred\n",
        "\n",
        "    mask = fool_target & correct_target_clean\n",
        "    denom = mask.sum().item()\n",
        "\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "\n",
        "    num = (mask & same_mistake).sum().item()\n",
        "    return 100.0 * num / denom\n",
        "\n",
        "# Perturbation quality metrics\n",
        "\n",
        "def ssim(images, adv_images):\n",
        "    \"\"\"\n",
        "    Computes the mean Structural Similarity Index (SSIM)\n",
        "    between original and adversarial images.\n",
        "\n",
        "    SSIM measures perceptual similarity considering:\n",
        "    - luminance\n",
        "    - contrast\n",
        "    - structure\n",
        "\n",
        "    SSIM = 1 means identical images.\n",
        "    Lower values indicate stronger or more visible perturbations.\n",
        "    \"\"\"\n",
        "    ssim_list = []\n",
        "\n",
        "    for i in range(images.size(0)):\n",
        "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy().astype(np.uint8)\n",
        "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
        "        ssim_list.append(ssim_val)\n",
        "\n",
        "    return float(np.mean(ssim_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack generation process\n",
        "The procedure is as follows:\n",
        "\n",
        "1. Attacks are generated on CIFAR10 test set using source model and then transferred to the target model.\n",
        "\n",
        "2. To do adversarial training we generate attacks on CIFAR10 train set and then use it to train the model on which were they generated.\n",
        "\n",
        "3. Attacks generated on the original models are used for evaluation. When calculating the metrics, we consider only those adversarial images which originals ware correctly classified by respected models."
      ],
      "metadata": {
        "id": "VXFIDJs6poP_"
      },
      "id": "VXFIDJs6poP_"
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_path = \"/content/drive/MyDrive/adv_data/models/vgg_epoch_80.pth\"\n",
        "resnet_model_path = \"/content/drive/MyDrive/adv_data/models/model_ResNet18_cifar10_20251112.pth\"\n",
        "adv_images_folder_path = \"/content/drive/MyDrive/adv_data/adversarial_images\" # \"/content/drive/MyDrive/\" is mandatory"
      ],
      "metadata": {
        "id": "jmzyB7P2nE38"
      },
      "id": "jmzyB7P2nE38",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beaef5c2",
      "metadata": {
        "id": "beaef5c2",
        "outputId": "00a13d42-d05e-4024-88f8-bc25cd1a84d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 90.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Original CIFAR10 Dataset\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG model\n",
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3YyqbGgGm0q",
        "outputId": "96628120-7f5c-41dc-efe5-0b163d699eb4"
      },
      "id": "r3YyqbGgGm0q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (block5): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet model\n",
        "model_resnet = ResNet18(3, 10)\n",
        "model_resnet.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
        "model_resnet.to(device)\n",
        "model_resnet.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQHNzY7Gp4w",
        "outputId": "217a828a-0cbf-49e7-e6b6-8d0875c94e84"
      },
      "id": "gTQHNzY7Gp4w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG -> Resnet\n",
        "source_model = model_vgg\n",
        "target_model = model_resnet\n",
        "dataset = testset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"VGG\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ouxTxJ-GPl",
        "outputId": "8c3ae73e-7b98-4d75-9fb3-0ffe7486aedf"
      },
      "id": "c4ouxTxJ-GPl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet -> VGG\n",
        "source_model = model_resnet\n",
        "target_model = model_vgg\n",
        "dataset = testset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"ResNet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZWLgkevh0cJ",
        "outputId": "2afae706-6896-4c84-e85b-3a6887e1aab3"
      },
      "id": "WZWLgkevh0cJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for VGG\n",
        "source_model = model_vgg\n",
        "dataset = trainset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"VGG\", train=True)"
      ],
      "metadata": {
        "id": "Jqp7ew8RFtUF"
      },
      "id": "Jqp7ew8RFtUF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for ResNet\n",
        "source_model = model_resnet\n",
        "dataset = trainset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"ResNet\", train=True)"
      ],
      "metadata": {
        "id": "EHlKSZhiGI5f"
      },
      "id": "EHlKSZhiGI5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "TO-rqThRjLwq"
      },
      "id": "TO-rqThRjLwq"
    },
    {
      "cell_type": "code",
      "source": [
        "aa_resnet_model_path = \"/content/drive/MyDrive/adv_data/models/resnet_AA_epoch_26.pth\"\n",
        "cw_resnet_model_path = \"/content/drive/MyDrive/adv_data/models/resnet_CW_epoch_29.pth\"\n",
        "aa_vgg_model_path = \"/content/drive/MyDrive/adv_data/models/VGG_AA_epoch_21.pth\"\n",
        "cw_vgg_model_path = \"/content/drive/MyDrive/adv_data/models/VGG_CW_epoch_27.pth\""
      ],
      "metadata": {
        "id": "E2P_XAxOWmLj"
      },
      "id": "E2P_XAxOWmLj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/adv_data/adversarial_images/test_VGG_PGD /content/"
      ],
      "metadata": {
        "id": "rVgv0w2viKA9"
      },
      "id": "rVgv0w2viKA9",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "attack_names = [\"FGSM\", \"PGD\", \"CW\", \"AutoAttack\", \"DeepFool\", \"OnePixel\"]\n",
        "vgg_model_paths = [vgg_model_path, aa_vgg_model_path, cw_vgg_model_path]\n",
        "resnet_model_paths = [resnet_model_path, aa_resnet_model_path, cw_resnet_model_path]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=mean, std=std)\n",
        "    ])"
      ],
      "metadata": {
        "id": "WAUHrwZhaHrl"
      },
      "id": "WAUHrwZhaHrl",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = AdversarialImageDataset(root_dir=os.path.join(adv_images_folder_path, f\"test_VGG_PGD\"), transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "5VNL2-ZIjwog"
      },
      "id": "5VNL2-ZIjwog",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()\n",
        "\n",
        "preds, labels = predict(model_vgg, loader, mean, std)\n",
        "print(preds[:10])\n",
        "print(labels[:10])"
      ],
      "metadata": {
        "id": "JB-giZGDfcbg"
      },
      "id": "JB-giZGDfcbg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = preds.eq(labels).sum() / len(labels)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "9T4emMM9cBrA",
        "outputId": "c83f715a-0c71-476f-f4ee-8dbb01dcc647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9T4emMM9cBrA",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8850)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}