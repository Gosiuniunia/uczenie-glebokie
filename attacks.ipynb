{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2446fdd",
   "metadata": {},
   "source": [
    "Źródła:\n",
    "\n",
    "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
    "\n",
    "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
    "\n",
    "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8708bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a884b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0597d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing VGG model\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Blok 3\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*4*4, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        # x = self.block5(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model_vgg = VGG16(num_classes=10)\n",
    "model_vgg.load_state_dict(torch.load(\"vgg_epoch_80.pth\", map_location=torch.device(\"cpu\")))\n",
    "# model_vgg.load_state_dict(torch.load(\"vgg_epoch_10.pth\", map_location=device))\n",
    "# model_vgg.to(device) \n",
    "model_vgg.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11b9050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing ResNet18 model\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main_path = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
    "                      stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                      stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(output_channels)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or input_channels != output_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(output_channels)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main_path(x) + self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
    "                      stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
    "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
    "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
    "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
    "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "model_resnet = ResNet18(3, 10)\n",
    "model_resnet.load_state_dict(torch.load(\"ResNet18_1_without_weight_decay/model_ResNet18_cifar10.pth\", map_location=torch.device(\"cpu\")))\n",
    "# model_resnet.load_state_dict(torch.load(\"ResNet18_1_without_weight_decay/model_ResNet18_cifar10.pth\", map_location=device))\n",
    "# model_resnet.to(device) \n",
    "model_resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaef5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Gradient Sign Method (FGSM) \n",
    "\n",
    "def fgsm(model, image, label, epsilon=0.1):\n",
    "    image.requires_grad_(True)\n",
    "    output = model(image)\n",
    "    loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    perturbation = epsilon * torch.sign(image.grad)\n",
    "    adversarial_image = image + perturbation\n",
    "    return adversarial_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projected Gradient Descent (PGD)\n",
    "\n",
    "def pgd(model, image, label, epsilon=0.03, alpha=0.05, num_iters=40):\n",
    "    original_image = image.clone()\n",
    "    adversarial_image = image.clone()\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        adversarial_image.requires_grad_(True)\n",
    "        output = model(adversarial_image)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gradient = adversarial_image.grad.data\n",
    "            adversarial_image += alpha * gradient.sign()\n",
    "            \n",
    "            perturbation = torch.clamp(adversarial_image - original_image, min=-epsilon, max=epsilon)\n",
    "            adversarial_image = torch.clamp(original_image + perturbation, 0, 1)\n",
    "\n",
    "        adversarial_image = adversarial_image.detach()\n",
    "                \n",
    "    return adversarial_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b45321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM(model_name=VGG16, device=cpu, attack_mode=default, targeted=False, normalization_used=False, eps=0.03137254901960784)\n",
      "PGD(model_name=VGG16, device=cpu, attack_mode=default, targeted=False, normalization_used=False, eps=0.03137254901960784, alpha=0.008888888888888889, steps=10, random_start=True)\n",
      "CW(model_name=VGG16, device=cpu, attack_mode=default, targeted=False, normalization_used=False, c=0.1, kappa=0, steps=1000, lr=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
    "# Attacks are generated using the VGG model and then transfered to the ResNet\n",
    "from torchattacks import PGD, FGSM, CW\n",
    "\n",
    "# Default parameters values\n",
    "atk_fgsm = FGSM(model_vgg, eps=8/255)\n",
    "atk_pgd = PGD(model_vgg, eps=8/255, alpha=2/225, steps=10, random_start=True)\n",
    "atk_cw = CW(model_vgg, c=0.1, steps=1000, lr=0.01)\n",
    "print(atk_fgsm)\n",
    "print(atk_pgd)\n",
    "print(atk_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a1d52c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch size: 100\n",
      "Number of correctly classified examples: 90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m adv_images_fgsm \u001b[38;5;241m=\u001b[39m atk_fgsm(images, labels)\n\u001b[0;32m     23\u001b[0m adv_images_pgd \u001b[38;5;241m=\u001b[39m atk_pgd(images, labels)\n\u001b[1;32m---> 24\u001b[0m adv_images_cw \u001b[38;5;241m=\u001b[39m \u001b[43matk_cw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\mgr\\.venv\\lib\\site-packages\\torchattacks\\attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[1;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs, labels, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\mgr\\.venv\\lib\\site-packages\\torchattacks\\attacks\\cw.py:89\u001b[0m, in \u001b[0;36mCW.forward\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m     86\u001b[0m cost \u001b[38;5;241m=\u001b[39m L2_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc \u001b[38;5;241m*\u001b[39m f_loss\n\u001b[0;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 89\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Update adversarial images\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\mgr\\.venv\\lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\mgr\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\mgr\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Samples generation using only correctly classified examples by vgg model\n",
    "\n",
    "def predict(model, images):\n",
    "    with torch.no_grad():\n",
    "        _, pred = model(images).max(1)\n",
    "    return pred\n",
    "\n",
    "n_examples = 100\n",
    "data_samples = [testset[i] for i in range(n_examples)]\n",
    "images = torch.stack([x[0] for x in data_samples])\n",
    "labels = torch.tensor([x[1] for x in data_samples])\n",
    "# images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "vgg_pred = predict(model_vgg, images)\n",
    "correct_mask = vgg_pred.eq(labels)\n",
    "images = images[correct_mask]\n",
    "labels = labels[correct_mask]\n",
    "\n",
    "print(f\"Original batch size: {n_examples}\")\n",
    "print(f\"Number of correctly classified examples: {images.size(0)}\")\n",
    "\n",
    "adv_images_fgsm = atk_fgsm(images, labels)\n",
    "adv_images_pgd = atk_pgd(images, labels)\n",
    "adv_images_cw = atk_cw(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82123111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])\n",
      "---------\n",
      "tensor([3, 0, 0, 0, 6, 6, 3, 6, 4, 9])\n",
      "tensor([5, 0, 0, 0, 4, 5, 3, 8, 4, 9])\n",
      "tensor([5, 0, 0, 0, 2, 3, 3, 8, 3, 9])\n",
      "-----------\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])\n",
      "tensor([3, 8, 0, 0, 6, 6, 5, 4, 3, 1])\n",
      "tensor([3, 8, 0, 0, 6, 6, 5, 4, 3, 0])\n",
      "tensor([3, 8, 0, 0, 6, 6, 5, 4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "vgg_pred_fgsm = predict(model_vgg, adv_images_fgsm)\n",
    "vgg_pred_pgd = predict(model_vgg, adv_images_pgd)\n",
    "vgg_pred_cw = predict(model_vgg, adv_images_cw)\n",
    "\n",
    "resnet_pred = predict(model_resnet, images)\n",
    "resnet_pred_fgsm = predict(model_resnet, adv_images_fgsm)\n",
    "resnet_pred_pgd = predict(model_resnet, adv_images_pgd)\n",
    "resnet_pred_cw = predict(model_resnet, adv_images_cw)\n",
    "\n",
    "# print(labels)\n",
    "# print(\"---------\")\n",
    "# print(vgg_pred_fgsm)\n",
    "# print(vgg_pred_pgd)\n",
    "# print(vgg_pred_cw)\n",
    "# print(\"-----------\")\n",
    "# print(resnet_pred)\n",
    "# print(resnet_pred_fgsm)\n",
    "# print(resnet_pred_pgd)\n",
    "# print(resnet_pred_cw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack efficiency metrics\n",
    "\n",
    "def accuracy(labels, preds):\n",
    "    total = len(labels)\n",
    "    correct = preds.eq(labels).sum().item()\n",
    "    test_acc = 100.*correct/total\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
    "    fool_source = source_pred != labels\n",
    "    fool_target = target_pred != labels\n",
    "    correct_target_pred = clean_target_pred == labels\n",
    "\n",
    "    P = fool_source.sum().item()\n",
    "    Q = (fool_source & fool_target & correct_target_pred).sum().item() # We count samples, which were correctly classified by target that fooled both models\n",
    "\n",
    "    fool_rate = Q / P if P > 0 else 0.0\n",
    "    return fool_rate\n",
    "\n",
    "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
    "    correct_target_pred = (clean_target_pred == labels)\n",
    "    fool_target = (target_pred != labels)\n",
    "    same_mistake = (source_pred == target_pred)\n",
    "\n",
    "    rate = (fool_target & same_mistake & correct_target_pred).sum().item() / (fool_target & correct_target_pred).sum().item() # We count the samples that fooled the model the same way taking into consideratoin only correctly classified samples by target\n",
    "    return rate\n",
    "\n",
    "# Perturbation quality metrics\n",
    "import sewar\n",
    "\n",
    "def ssim(images, adv_images):  # Structural Similarity Index Metric (SSIM) measures perceptual similarity between two images, considering luminance, contrast, and structure. We want to maximize this value\n",
    "    ssim_list = []\n",
    "\n",
    "    for i in range(images.size(0)):\n",
    "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "        img_1 = (img_1 * 255).clip(0, 255).astype(np.uint8)\n",
    "        img_2 = (img_2 * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
    "        ssim_list.append(ssim_val)\n",
    "    \n",
    "    return float(np.mean(ssim_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76a43977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Attack Efficiency Metrics ===\n",
      "  Attack  VGG Accuracy  ResNet Accuracy (originally correct only)  \\\n",
      "0   FGSM          50.0                                       70.0   \n",
      "1    PGD          10.0                                       60.0   \n",
      "2     CW          20.0                                       70.0   \n",
      "\n",
      "   Fooling Rate (VGG -> ResNet)  Same Mistake Rate (VGG -> ResNet)  \n",
      "0                      0.400000                           0.333333  \n",
      "1                      0.444444                           0.250000  \n",
      "2                      0.375000                           0.333333  \n",
      "=== SSIM values ===\n",
      "SSIM for FGSM: 0.9963103156567119\n",
      "SSIM for PDG: 0.9969092399852271\n",
      "SSIM for CW: 0.9996308475728009\n"
     ]
    }
   ],
   "source": [
    "# Metric values\n",
    "import pandas as pd\n",
    "\n",
    "correct_mask_resnet = resnet_pred.eq(labels)\n",
    "attack_metrics = {\n",
    "    \"Attack\": [\"FGSM\", \"PGD\", \"CW\"],\n",
    "    \"VGG Accuracy\": [\n",
    "        accuracy(labels, vgg_pred_fgsm),\n",
    "        accuracy(labels, vgg_pred_pgd),\n",
    "        accuracy(labels, vgg_pred_cw)\n",
    "    ],\n",
    "    \"ResNet Accuracy (originally correct only)\": [\n",
    "        accuracy(labels[correct_mask_resnet], resnet_pred_fgsm[correct_mask_resnet]),\n",
    "        accuracy(labels[correct_mask_resnet], resnet_pred_pgd[correct_mask_resnet]),\n",
    "        accuracy(labels[correct_mask_resnet], resnet_pred_cw[correct_mask_resnet])\n",
    "    ],\n",
    "    \"Fooling Rate (VGG -> ResNet)\": [\n",
    "        fooling_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
    "        fooling_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
    "        fooling_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
    "    ],\n",
    "    \"Same Mistake Rate (VGG -> ResNet)\": [\n",
    "        same_mistake_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
    "        same_mistake_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
    "        same_mistake_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_attack = pd.DataFrame(attack_metrics)\n",
    "print(\"=== Attack Efficiency Metrics ===\")\n",
    "print(df_attack)\n",
    "\n",
    "print(\"=== SSIM values ===\")\n",
    "print(\"SSIM for FGSM:\", ssim(images, adv_images_fgsm))\n",
    "print(\"SSIM for PDG:\", ssim(images, adv_images_pgd))\n",
    "print(\"SSIM for CW:\", ssim(images, adv_images_cw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbdb58",
   "metadata": {},
   "source": [
    "For n_examples = 10\n",
    "=== Attack Efficiency Metrics ===\n",
    "  Attack  VGG Accuracy  ResNet Accuracy (originally correct only)  \\\n",
    "0   FGSM          50.0                                       70.0   \n",
    "1    PGD          10.0                                       60.0   \n",
    "2     CW          20.0                                       70.0   \n",
    "\n",
    "   Fooling Rate (VGG -> ResNet)  Same Mistake Rate (VGG -> ResNet)  \n",
    "0                      0.400000                           0.333333  \n",
    "1                      0.444444                           0.250000  \n",
    "2                      0.375000                           0.333333  \n",
    "=== SSIM values ===\n",
    "SSIM for FGSM: 0.9963103156567119\n",
    "SSIM for PDG: 0.9969092399852271\n",
    "SSIM for CW: 0.9996308475728009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec60d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8783362..1.5628136].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wisualization of one sample for VGG prediction\n",
    "index = 4 # Index number must be lower than correctly classified examples\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "fig.suptitle(\"VGG\")\n",
    "axs[0].imshow(images[index].permute(1, 2, 0).detach().numpy())\n",
    "axs[0].set_title(f\"Original: {labels[index]}\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(adv_images_fgsm[index].permute(1, 2, 0).detach().numpy())\n",
    "axs[1].set_title(f\"FGSM: {vgg_pred_fgsm[index]}\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(adv_images_pgd[index].permute(1, 2, 0).detach().numpy())\n",
    "axs[2].set_title(f\"FGSM: {vgg_pred_pgd[index]}\")\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(adv_images_cw[index].permute(1, 2, 0).detach().numpy())\n",
    "axs[3].set_title(f\"FGSM: {vgg_pred_cw[index]}\")\n",
    "axs[3].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
