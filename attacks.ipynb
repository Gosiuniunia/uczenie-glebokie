{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gosiuniunia/uczenie-glebokie/blob/main/attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2446fdd",
      "metadata": {
        "id": "f2446fdd"
      },
      "source": [
        "Źródła:\n",
        "\n",
        "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
        "\n",
        "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
        "\n",
        "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZLw7AZ3ekD88",
        "outputId": "a1b39d98-1877-48dc-9d82-905093e4fd5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZLw7AZ3ekD88",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchattacks\n",
        "!pip install sewar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmV4mnuJpq8A",
        "outputId": "eca1d910-ce65-4360-9438-04d6165d2728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hmV4mnuJpq8A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (0.24.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.0.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.8.2->torchattacks) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.3)\n",
            "Collecting sewar\n",
            "  Downloading sewar-0.4.6.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sewar) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sewar) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sewar) (11.3.0)\n",
            "Building wheels for collected packages: sewar\n",
            "  Building wheel for sewar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sewar: filename=sewar-0.4.6-py3-none-any.whl size=11418 sha256=99fb9324320abc19d5f1ed5dc20e4e10a910b49ac4b621b7d87fe93a1d1edd65\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/4e/29/b15a3d425c5f0fe8f461cbfdaf4fa98ef203fed97ce1df6695\n",
            "Successfully built sewar\n",
            "Installing collected packages: sewar\n",
            "Successfully installed sewar-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8708bca8",
      "metadata": {
        "id": "8708bca8",
        "outputId": "4163f4c6-7ec9-41ed-96f2-b7f891b5546d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2e30099890>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import sewar\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a884b19",
      "metadata": {
        "id": "3a884b19",
        "outputId": "afeea5cf-02fd-424a-daf0-88dbd5bf026d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_path = \"/content/drive/MyDrive/vgg_epoch_80.pth\"\n",
        "resnet_model_path = \"/content/drive/MyDrive/model_ResNet18_cifar10_20251112.pth\"\n",
        "images_save_folder_path = \"/content/drive/MyDrive/adv_files\" # \"/content/drive/MyDrive/\" is mandatory"
      ],
      "metadata": {
        "id": "jmzyB7P2nE38"
      },
      "id": "jmzyB7P2nE38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc0597d1",
      "metadata": {
        "collapsed": true,
        "id": "dc0597d1",
        "outputId": "cf9b9d6b-15e0-4609-c958-d32012bf96c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (block5): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Preparing VGG model\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Blok 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256*4*4, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        # x = self.block5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11b9050",
      "metadata": {
        "collapsed": true,
        "id": "b11b9050",
        "outputId": "ea3e140c-e655-4d54-a126-7c94fb818573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Preparing ResNet18 model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main_path = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                      stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main_path(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
        "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
        "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
        "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model_resnet = ResNet18(3, 10)\n",
        "model_resnet.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
        "model_resnet.to(device)\n",
        "model_resnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beaef5c2",
      "metadata": {
        "id": "beaef5c2"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "]) # only one transform is used because augumentation is not taken into consideration when generating attacks\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "def predict(model, images):\n",
        "    with torch.no_grad():\n",
        "        _, pred = model(images).max(1)\n",
        "    return pred\n",
        "\n",
        "def choose_images(n_examples, dataset, model):\n",
        "  \"\"\"\n",
        "  This function chooses a random sample of given size from given dataset.\n",
        "  It returns those that were correctly classified by the given model.\n",
        "  \"\"\"\n",
        "\n",
        "  indices = random.sample(range(len(dataset)), n_examples)\n",
        "  data_samples = [testset[i] for i in indices]\n",
        "\n",
        "  adv_images = torch.stack([x[0] for x in data_samples])\n",
        "  adv_labels = torch.tensor([x[1] for x in data_samples])\n",
        "  adv_images, adv_labels = adv_images.to(device), adv_labels.to(device)\n",
        "\n",
        "  model_pred = predict(model, adv_images)\n",
        "  correct_mask = model_pred.eq(adv_labels)\n",
        "  adv_images = adv_images[correct_mask]\n",
        "  adv_labels = adv_labels[correct_mask]\n",
        "\n",
        "  print(f\"Original batch size: {n_examples}\")\n",
        "  print(f\"Number of correctly classified examples: {adv_images.size(0)}\")\n",
        "\n",
        "  return adv_images, adv_labels"
      ],
      "metadata": {
        "id": "Z0srJjIe1DfT"
      },
      "id": "Z0srJjIe1DfT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1d52c7",
      "metadata": {
        "id": "2a1d52c7",
        "outputId": "5499d363-b1f4-4bb9-a578-34d3bd053486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original batch size: 1000\n",
            "Number of correctly classified examples: 871\n"
          ]
        }
      ],
      "source": [
        "# Samples and attack generation\n",
        "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
        "from torchattacks import PGD, FGSM, CW # more attacks will be added\n",
        "\n",
        "# Parameters\n",
        "n_examples = 1000\n",
        "dataset = testset\n",
        "attacking_model = model_vgg\n",
        "\n",
        "images, labels = choose_images(n_examples, dataset, attacking_model)\n",
        "\n",
        "atk_fgsm = FGSM(attacking_model, eps=8/255)\n",
        "atk_fgsm.set_normalization_used(mean, std)\n",
        "adv_images_fgsm = atk_fgsm(images, labels)\n",
        "\n",
        "atk_pgd = PGD(attacking_model, eps=8/255, alpha=2/225, steps=10, random_start=True)\n",
        "atk_pgd.set_normalization_used(mean, std)\n",
        "adv_images_pgd = atk_pgd(images, labels)\n",
        "\n",
        "atk_cw = CW(attacking_model, c=0.1, steps=1000, lr=0.01)\n",
        "atk_cw.set_normalization_used(mean, std)\n",
        "adv_images_cw = atk_cw(images, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82123111",
      "metadata": {
        "id": "82123111"
      },
      "outputs": [],
      "source": [
        "vgg_pred_fgsm = predict(model_vgg, adv_images_fgsm)\n",
        "vgg_pred_pgd = predict(model_vgg, adv_images_pgd)\n",
        "vgg_pred_cw = predict(model_vgg, adv_images_cw)\n",
        "\n",
        "resnet_pred = predict(model_resnet, images)\n",
        "resnet_pred_fgsm = predict(model_resnet, adv_images_fgsm)\n",
        "resnet_pred_pgd = predict(model_resnet, adv_images_pgd)\n",
        "resnet_pred_cw = predict(model_resnet, adv_images_cw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c936e98a",
      "metadata": {
        "id": "c936e98a"
      },
      "outputs": [],
      "source": [
        "# Attack efficiency metrics\n",
        "\n",
        "def attack_success_rate(labels, preds):\n",
        "    \"\"\"\n",
        "    Computes the Attack Success Rate (ASR).\n",
        "    Measures how many attacks succeeded.\n",
        "    \"\"\"\n",
        "    total = len(labels)\n",
        "    succeeded = (preds != labels).sum().item()\n",
        "    return 100.0 * succeeded / total\n",
        "\n",
        "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the fooling rate for transfer attacks.\n",
        "\n",
        "    - source_pred: predictions of the SOURCE model on adversarial images\n",
        "    - target_pred: predictions of the TARGET model on adversarial images\n",
        "    - clean_target_pred: predictions of the TARGET model on clean images\n",
        "\n",
        "    We measure cases where:\n",
        "    1) the adversarial sample fools the SOURCE model,\n",
        "    2) it also fools the TARGET model,\n",
        "    3) but the TARGET classified the clean version correctly.\n",
        "\n",
        "    The fooling rate is: Q / P\n",
        "    where:\n",
        "        P = number of samples that fooled the source\n",
        "        Q = number of samples that fooled both models\n",
        "    \"\"\"\n",
        "    fool_source = source_pred != labels\n",
        "    fool_target = target_pred != labels\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "\n",
        "    P = fool_source.sum().item()\n",
        "    Q = (fool_source & fool_target & correct_target_clean).sum().item()\n",
        "\n",
        "    return 100.0 * Q / P if P > 0 else 0.0\n",
        "\n",
        "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the rate at which both the source and target models make\n",
        "    the SAME wrong prediction on adversarial samples.\n",
        "\n",
        "    We consider ONLY samples where:\n",
        "    - the target model classified the CLEAN image correctly\n",
        "    - the target model is fooled on the adversarial image\n",
        "\n",
        "    Among those, we measure how often:\n",
        "        source_pred == target_pred (same incorrect class)\n",
        "    \"\"\"\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "    fool_target = target_pred != labels\n",
        "    same_mistake = source_pred == target_pred\n",
        "\n",
        "    mask = fool_target & correct_target_clean\n",
        "    denom = mask.sum().item()\n",
        "\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "\n",
        "    num = (mask & same_mistake).sum().item()\n",
        "    return 100.0 * num / denom\n",
        "\n",
        "# Perturbation quality metrics\n",
        "\n",
        "def ssim(images, adv_images):\n",
        "    \"\"\"\n",
        "    Computes the mean Structural Similarity Index (SSIM)\n",
        "    between original and adversarial images.\n",
        "\n",
        "    SSIM measures perceptual similarity considering:\n",
        "    - luminance\n",
        "    - contrast\n",
        "    - structure\n",
        "\n",
        "    SSIM = 1 means identical images.\n",
        "    Lower values indicate stronger or more visible perturbations.\n",
        "    \"\"\"\n",
        "    ssim_list = []\n",
        "\n",
        "    for i in range(images.size(0)):\n",
        "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "        img_1 = (img_1 * 255).clip(0, 255).astype(np.uint8)\n",
        "        img_2 = (img_2 * 255).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
        "        ssim_list.append(ssim_val)\n",
        "\n",
        "    return float(np.mean(ssim_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a43977",
      "metadata": {
        "id": "76a43977",
        "outputId": "41b83626-22da-4830-8718-be789c04e73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of correctly classified examples for ResNet: 853\n",
            "=== Attack Efficiency Metrics ===\n",
            "  Attack     VGG ASR  ResNet ASR (originally correct only)  \\\n",
            "0   FGSM   94.718714                             47.479484   \n",
            "1    PGD  100.000000                             64.009379   \n",
            "2     CW  100.000000                              1.758499   \n",
            "\n",
            "   Fooling Rate (VGG -> ResNet)  Same Mistake Rate (VGG -> ResNet)  \n",
            "0                     48.969697                          63.950617  \n",
            "1                     62.686567                          95.970696  \n",
            "2                      1.722158                          86.666667  \n",
            "=== SSIM values ===\n",
            "SSIM for FGSM: 0.9369262695741961\n",
            "SSIM for PGD: 0.9582249748340417\n",
            "SSIM for CW: 0.998044740450877\n"
          ]
        }
      ],
      "source": [
        "# Metric values\n",
        "\"\"\"\n",
        "ASR - ile % ataków się udało\n",
        "Fooling rate - ile % ataków co zmyliło source zmyliło też target\n",
        "Same mistake - ile % to był ten sam błąd\n",
        "wszystko pod warunkiem że target poprawnie sklasyfikował oryginał\n",
        "\"\"\"\n",
        "\n",
        "# ResNet ASR is counted only when clean images are classified correctly\n",
        "\n",
        "correct_mask_resnet = resnet_pred.eq(labels)\n",
        "print(f\"Number of correctly classified examples for ResNet: {correct_mask_resnet.sum()}\")\n",
        "attack_metrics = {\n",
        "    \"Attack\": [\"FGSM\", \"PGD\", \"CW\"],\n",
        "    \"VGG ASR\": [\n",
        "        attack_success_rate(labels, vgg_pred_fgsm),\n",
        "        attack_success_rate(labels, vgg_pred_pgd),\n",
        "        attack_success_rate(labels, vgg_pred_cw)\n",
        "    ],\n",
        "    \"ResNet ASR\": [\n",
        "        attack_success_rate(labels[correct_mask_resnet], resnet_pred_fgsm[correct_mask_resnet]),\n",
        "        attack_success_rate(labels[correct_mask_resnet], resnet_pred_pgd[correct_mask_resnet]),\n",
        "        attack_success_rate(labels[correct_mask_resnet], resnet_pred_cw[correct_mask_resnet])\n",
        "    ],\n",
        "    \"Fooling Rate (VGG -> ResNet)\": [\n",
        "        fooling_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
        "        fooling_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
        "        fooling_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
        "    ],\n",
        "    \"Same Mistake Rate (VGG -> ResNet)\": [\n",
        "        same_mistake_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
        "        same_mistake_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
        "        same_mistake_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_attack = pd.DataFrame(attack_metrics)\n",
        "print(\"=== Attack Efficiency Metrics ===\")\n",
        "print(df_attack)\n",
        "\n",
        "print(\"=== SSIM values ===\")\n",
        "print(\"SSIM for FGSM:\", ssim(images, adv_images_fgsm))\n",
        "print(\"SSIM for PGD:\", ssim(images, adv_images_pgd))\n",
        "print(\"SSIM for CW:\", ssim(images, adv_images_cw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec60d37f",
      "metadata": {
        "id": "ec60d37f",
        "outputId": "2f99aa3f-613c-4819-fe1a-7796583d0fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Wisualization of one sample for VGG prediction\n",
        "index = 3 # Index number must be lower than correctly classified examples\n",
        "class_names = testset.classes\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
        "fig.suptitle(\"VGG\")\n",
        "axs[0].imshow((images[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[0].set_title(f\"Original: {class_names[labels[index]]}\")\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow((adv_images_fgsm[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[1].set_title(f\"FGSM: {class_names[vgg_pred_fgsm[index]]}\")\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow((adv_images_pgd[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[2].set_title(f\"PGD: {class_names[vgg_pred_pgd[index]]}\")\n",
        "axs[2].axis('off')\n",
        "\n",
        "axs[3].imshow((adv_images_cw[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[3].set_title(f\"CW: {class_names[vgg_pred_cw[index]]}\")\n",
        "axs[3].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save images to the designated folder\n",
        "\n",
        "def save_images(images, labels, path, folder_name=None):\n",
        "  \"\"\"\n",
        "  This function saves given images with their labels in the given folder.\n",
        "  Subfolder can be specified. Each image is saved as adv_image_{index}_label_{labels[index]}.png,\n",
        "  \"\"\"\n",
        "  try:\n",
        "    path = os.path.join(path, folder_name)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  for i, (image_tensor, label) in enumerate(zip(images, labels)):\n",
        "    image_np = (images[i].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(image_np)\n",
        "\n",
        "    filename = f\"adv_image_{i}_label_{labels[i]}.png\"\n",
        "    filepath = os.path.join(path, filename)\n",
        "    image_pil.save(filepath)\n"
      ],
      "metadata": {
        "id": "jAlQUFmRudGS"
      },
      "id": "jAlQUFmRudGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_images(adv_images_pgd, labels, images_save_folder_path, \"pgd\")"
      ],
      "metadata": {
        "id": "4IZWTJqPKhEW"
      },
      "id": "4IZWTJqPKhEW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading all of the images in specified folder to torch dataset\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AdversarialImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class loads the images from specified folder (save_images generated folder)\n",
        "    and transforms it to torch dataset for future learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".png\"):\n",
        "                self.image_files.append(file)\n",
        "\n",
        "        self.image_files.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        label = int(img_name.split(\"_\")[-1].split(\".\")[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "d38m__uqHJAY"
      },
      "id": "d38m__uqHJAY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to load the adversarial dataset and dataloader for additional training\n",
        "\n",
        "subfolder_name = \"pgd\"\n",
        "dataset_pgd = AdversarialImageDataset(root_dir=os.path.join(images_save_folder_path, subfolder_name), transform=transform)\n",
        "loader_pgd = DataLoader(dataset_pgd, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "Xjc4ktCCNZP2"
      },
      "id": "Xjc4ktCCNZP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to get images and labels for metrics\n",
        "\n",
        "adv_images = torch.stack([x[0] for x in dataset_pgd])\n",
        "adv_labels = torch.tensor([x[1] for x in dataset_pgd])\n",
        "adv_images, adv_labels = adv_images.to(device), adv_labels.to(device)\n",
        "\n",
        "model_pred = predict(model_vgg, adv_images)\n",
        "print(adv_labels[:5].cpu().tolist(), model_pred[:5].cpu().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfkORouiIirG",
        "outputId": "c2a87288-1b62-427c-a12f-9977b4e7e64e"
      },
      "id": "rfkORouiIirG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 4, 0, 2, 1] [1, 0, 2, 6, 8]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}