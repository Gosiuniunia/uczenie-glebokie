{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gosiuniunia/uczenie-glebokie/blob/main/attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2446fdd",
      "metadata": {
        "id": "f2446fdd"
      },
      "source": [
        "Źródła:\n",
        "\n",
        "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
        "\n",
        "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
        "\n",
        "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023.\n",
        "\n",
        "SU, Jiawei; VARGAS, Danilo Vasconcellos; SAKURAI, Kouichi. One pixel attack for fooling deep neural networks. IEEE Transactions on Evolutionary Computation, 2019, 23.5: 828-841.\n",
        "\n",
        "WONG, Eric; RICE, Leslie; KOLTER, J. Zico. Fast is better than free: Revisiting adversarial training. arXiv preprint arXiv:2001.03994, 2020.\n",
        "\n",
        "MOOSAVI-DEZFOOLI, Seyed-Mohsen; FAWZI, Alhussein; FROSSARD, Pascal. Deepfool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. p. 2574-2582.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZLw7AZ3ekD88",
        "outputId": "d1777389-bc30-4ee2-a338-1e8a424ba228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZLw7AZ3ekD88",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchattacks\n",
        "!pip install sewar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmV4mnuJpq8A",
        "outputId": "43a8fb6b-a45e-4168-f9fe-d26ad3757a14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hmV4mnuJpq8A",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (0.24.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.0.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.8.2->torchattacks) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.3)\n",
            "Requirement already satisfied: sewar in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sewar) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sewar) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sewar) (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "8708bca8",
      "metadata": {
        "id": "8708bca8",
        "outputId": "79bef918-3253-40ab-b6ca-07270e5e8fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a938c875810>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import sewar\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
        "\n",
        "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
        "from torchattacks import PGD, FGSM, CW, AutoAttack, DeepFool, OnePixel\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "3a884b19",
      "metadata": {
        "id": "3a884b19",
        "outputId": "011068e5-8a5f-4ebe-8b03-80320e4e87d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "dc0597d1",
      "metadata": {
        "collapsed": true,
        "id": "dc0597d1"
      },
      "outputs": [],
      "source": [
        "# VGG model architecture\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Blok 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256*4*4, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        # x = self.block5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "b11b9050",
      "metadata": {
        "collapsed": true,
        "id": "b11b9050"
      },
      "outputs": [],
      "source": [
        "# ResNet18 model architecture\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main_path = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                      stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main_path(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
        "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
        "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
        "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_correct_images(dataset, model, correct_only=True, batch_size=64):\n",
        "    \"\"\"\n",
        "    This function chooses correctly classified images from given dataset in batches.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct_images, correct_labels = [], []\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    normalize = transforms.Normalize(mean, std)\n",
        "    print(f\"Number of images in dataset: {len(dataset)}\")\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        if correct_only:\n",
        "            images_norm = normalize(images)\n",
        "            with torch.no_grad():\n",
        "                preds = model(images_norm).argmax(1)\n",
        "            mask = preds.eq(labels)\n",
        "            if mask.any():\n",
        "                correct_images.append(images[mask].cpu())\n",
        "                correct_labels.append(labels[mask].cpu())\n",
        "\n",
        "            del images, labels, preds, mask\n",
        "            torch.cuda.empty_cache()\n",
        "        else:\n",
        "            correct_images.append(images.cpu())\n",
        "            correct_labels.append(labels.cpu())\n",
        "\n",
        "            del images, labels\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    correct_images = torch.cat(correct_images).to(device)\n",
        "    correct_labels = torch.cat(correct_labels).to(device)\n",
        "    print(f\"Number of images to generate attacks: {correct_images.size(0)}\")\n",
        "\n",
        "    return correct_images, correct_labels\n"
      ],
      "metadata": {
        "id": "SDz41IAtzYC5"
      },
      "id": "SDz41IAtzYC5",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "c936e98a",
      "metadata": {
        "id": "c936e98a"
      },
      "outputs": [],
      "source": [
        "# Attack efficiency metrics\n",
        "\n",
        "def attack_success_rate(labels, preds):\n",
        "    \"\"\"\n",
        "    Computes the Attack Success Rate (ASR).\n",
        "    Measures how many attacks succeeded.\n",
        "    \"\"\"\n",
        "    labels, preds = labels.to(device), preds.to(device)\n",
        "    total = len(labels)\n",
        "    succeeded = (preds != labels).sum().item()\n",
        "    return 100.0 * succeeded / total\n",
        "\n",
        "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the fooling rate for transfer attacks.\n",
        "\n",
        "    - source_pred: predictions of the SOURCE model on adversarial images\n",
        "    - target_pred: predictions of the TARGET model on adversarial images\n",
        "    - clean_target_pred: predictions of the TARGET model on clean images\n",
        "\n",
        "    We measure cases where:\n",
        "    1) the adversarial sample fools the SOURCE model,\n",
        "    2) it also fools the TARGET model,\n",
        "    3) but the TARGET classified the clean version correctly.\n",
        "\n",
        "    The fooling rate is: Q / P\n",
        "    where:\n",
        "        P = number of samples that fooled the source\n",
        "        Q = number of samples that fooled both models\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    fool_source = source_pred != labels\n",
        "    fool_target = target_pred != labels\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "\n",
        "    P = fool_source.sum().item()\n",
        "    Q = (fool_source & fool_target & correct_target_clean).sum().item()\n",
        "\n",
        "    return 100.0 * Q / P if P > 0 else 0.0\n",
        "\n",
        "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the rate at which both the source and target models make\n",
        "    the SAME wrong prediction on adversarial samples.\n",
        "\n",
        "    We consider ONLY samples where:\n",
        "    - the target model classified the CLEAN image correctly\n",
        "    - the target model is fooled on the adversarial image\n",
        "\n",
        "    Among those, we measure how often:\n",
        "        source_pred == target_pred (same incorrect class)\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "    fool_target = target_pred != labels\n",
        "    same_mistake = source_pred == target_pred\n",
        "\n",
        "    mask = fool_target & correct_target_clean\n",
        "    denom = mask.sum().item()\n",
        "\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "\n",
        "    num = (mask & same_mistake).sum().item()\n",
        "    return 100.0 * num / denom\n",
        "\n",
        "# Perturbation quality metrics\n",
        "\n",
        "def ssim(images, adv_images):\n",
        "    \"\"\"\n",
        "    Computes the mean Structural Similarity Index (SSIM)\n",
        "    between original and adversarial images.\n",
        "\n",
        "    SSIM measures perceptual similarity considering:\n",
        "    - luminance\n",
        "    - contrast\n",
        "    - structure\n",
        "\n",
        "    SSIM = 1 means identical images.\n",
        "    Lower values indicate stronger or more visible perturbations.\n",
        "    \"\"\"\n",
        "    ssim_list = []\n",
        "\n",
        "    for i in range(images.size(0)):\n",
        "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "        img_1 = (img_1 * 255).clip(0, 255).astype(np.uint8)\n",
        "        img_2 = (img_2 * 255).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
        "        ssim_list.append(ssim_val)\n",
        "\n",
        "    return float(np.mean(ssim_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save images to the designated folder\n",
        "\n",
        "def save_images(images, labels, path, folder_name=None):\n",
        "  \"\"\"\n",
        "  This function saves given images with their labels in the given folder.\n",
        "  Subfolder can be specified. Each image is saved as adv_image_{index}_label_{labels[index]}.png,\n",
        "  \"\"\"\n",
        "  try:\n",
        "    path = os.path.join(path, folder_name)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  for i, (image_tensor, label) in enumerate(zip(images, labels)):\n",
        "    img = image_tensor.detach().permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).clip(0,255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(img)\n",
        "\n",
        "    filename = f\"adv_image_{i}_label_{int(label)}.png\"\n",
        "    filepath = os.path.join(path, filename)\n",
        "    image_pil.save(filepath)"
      ],
      "metadata": {
        "id": "jAlQUFmRudGS"
      },
      "id": "jAlQUFmRudGS",
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all of the images in specified folder to torch dataset\n",
        "\n",
        "class AdversarialImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class loads the images from specified folder (save_images generated folder)\n",
        "    and transforms it to torch dataset for future learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".png\"):\n",
        "                self.image_files.append(file)\n",
        "\n",
        "        self.image_files.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        label = int(img_name.split(\"_\")[-1].split(\".\")[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "DZjOmzanJq9y"
      },
      "id": "DZjOmzanJq9y",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_images(source_model, images, labels, source_name, train=False, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generates adversarial images for all attacks in batches to avoid CUDA OOM.\n",
        "    \"\"\"\n",
        "    attack_configs = [\n",
        "        {\"name\": \"FGSM\", \"atk\": FGSM(source_model, eps=8/255)},\n",
        "        {\"name\": \"PGD\", \"atk\": PGD(source_model, eps=8/255, alpha=2/255, steps=20, random_start=True)},\n",
        "        {\"name\": \"CW\", \"atk\": CW(source_model, c=1, steps=300, lr=0.01)},\n",
        "        {\"name\": \"AutoAttack\", \"atk\": AutoAttack(source_model, norm=\"Linf\", eps=8/255)},\n",
        "        {\"name\": \"DeepFool\", \"atk\": DeepFool(source_model, steps=50, overshoot=0.02)},\n",
        "        {\"name\": \"OnePixel\", \"atk\": OnePixel(source_model, pixels=1, steps=50, popsize=20)}\n",
        "    ]\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(images, labels)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for config in attack_configs:\n",
        "        attack_name = config[\"name\"]\n",
        "        atk = config[\"atk\"]\n",
        "        print(f\"Generating {attack_name} attacks\")\n",
        "\n",
        "        if attack_name == \"AutoAttack\":\n",
        "            atk.attacks_to_run = ['apgd-ce']\n",
        "\n",
        "        atk.set_normalization_used(mean, std)\n",
        "        adv_images_list = []\n",
        "        adv_labels_list = []\n",
        "\n",
        "        for batch_images, batch_labels in loader:\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            adv_batch = atk(batch_images, batch_labels)\n",
        "\n",
        "            adv_images_list.append(adv_batch.cpu())\n",
        "            adv_labels_list.append(batch_labels.cpu())\n",
        "\n",
        "            del batch_images, batch_labels, adv_batch\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        adv_images_all = torch.cat(adv_images_list)\n",
        "        adv_labels_all = torch.cat(adv_labels_list)\n",
        "\n",
        "        folder_prefix = \"train\" if train else \"test\"\n",
        "        save_images(adv_images_all, adv_labels_all, adv_images_folder_path, f\"{folder_prefix}_{source_name}_{attack_name}\")\n"
      ],
      "metadata": {
        "id": "URG21dM3lQyK"
      },
      "id": "URG21dM3lQyK",
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "beaef5c2",
      "metadata": {
        "id": "beaef5c2"
      },
      "outputs": [],
      "source": [
        "# Original CIFAR10 Dataset\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The procedure is as follows:\n",
        "\n",
        "1. Attacks are generated on test set using source model and then transferred to the target model. In evaluation we consider only those adversarial images which originals ware correctly classified by respected models.\n",
        "\n",
        "2. To do adversarial training we generate attacks on the whole train set and then use it to train the model on which were they generated.\n",
        "\n",
        "3. To do next evaluation, we again generate attacks on test set and repeat 1st step."
      ],
      "metadata": {
        "id": "VXFIDJs6poP_"
      },
      "id": "VXFIDJs6poP_"
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_path = \"/content/drive/MyDrive/vgg_epoch_80.pth\"\n",
        "adv_vgg_model_path = \"\"\n",
        "resnet_model_path = \"/content/drive/MyDrive/model_ResNet18_cifar10_20251112.pth\"\n",
        "adv_resnet_model_path = \"\"\n",
        "adv_images_folder_path = \"/content/drive/MyDrive/adversarial_images\" # \"/content/drive/MyDrive/\" is mandatory"
      ],
      "metadata": {
        "id": "jmzyB7P2nE38"
      },
      "id": "jmzyB7P2nE38",
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG model\n",
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3YyqbGgGm0q",
        "outputId": "e1440b7e-02f2-472f-ed3c-50dad8e32f66"
      },
      "id": "r3YyqbGgGm0q",
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (block5): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet model\n",
        "model_resnet = ResNet18(3, 10)\n",
        "model_resnet.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
        "model_resnet.to(device)\n",
        "model_resnet.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQHNzY7Gp4w",
        "outputId": "977b9bbf-7cf9-4dc0-893f-f0711e4a199f"
      },
      "id": "gTQHNzY7Gp4w",
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG -> Resnet\n",
        "source_model = model_vgg\n",
        "target_model = model_resnet\n",
        "dataset = testset\n",
        "images, labels = choose_correct_images(dataset, source_model)\n",
        "generate_adversarial_images(source_model, images, labels, \"VGG\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ouxTxJ-GPl",
        "outputId": "0d0d8938-36f8-4ec9-ef00-b0ce12428217"
      },
      "id": "c4ouxTxJ-GPl",
      "execution_count": 167,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in dataset: 10000\n",
            "Number of images to generate attacks: 8852\n",
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet -> VGG\n",
        "source_model = model_resnet\n",
        "target_model = model_vgg\n",
        "dataset = testset\n",
        "images, labels = choose_correct_images(dataset, source_model)\n",
        "generate_adversarial_images(source_model, images, labels, \"ResNet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZWLgkevh0cJ",
        "outputId": "80b7bbf7-d2e5-4fc7-c870-068427bacb0d"
      },
      "id": "WZWLgkevh0cJ",
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in dataset: 10000\n",
            "Number of images to generate attacks: 9295\n",
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for VGG\n",
        "source_model = model_vgg\n",
        "dataset = trainset\n",
        "images, labels = choose_correct_images(trainset, source_model, correct_only=False)\n",
        "generate_adversarial_images(source_model, images, labels, \"VGG\", train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqp7ew8RFtUF",
        "outputId": "337db151-cfcd-492f-8154-1b6304a5f77f"
      },
      "id": "Jqp7ew8RFtUF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in dataset: 50000\n",
            "Number of images to generate attacks: 50000\n",
            "Generating FGSM attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for ResNet\n",
        "source_model = model_resnet\n",
        "dataset = trainset\n",
        "images, labels = choose_correct_images(trainset, source_model, correct_only=False)\n",
        "generate_adversarial_images(source_model, images, labels, \"ResNet\", train=True)"
      ],
      "metadata": {
        "id": "EHlKSZhiGI5f"
      },
      "id": "EHlKSZhiGI5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to load the adversarial dataset and dataloader for additional training - load model normally\n",
        "subfolder_name = \"test_VGG_FGSM\"\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "adv_dataset = AdversarialImageDataset(root_dir=os.path.join(adv_images_folder_path, subfolder_name), transform=transform)\n",
        "adv_loader = DataLoader(adv_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "Xjc4ktCCNZP2"
      },
      "id": "Xjc4ktCCNZP2",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining 2 or more adversarial datasets\n",
        "attack_subfolders = [\"test_VGG_FGSM\", \"test_VGG_PGD\"]\n",
        "list_of_datasets = []\n",
        "for subfolder in attack_subfolders:\n",
        "    dataset = AdversarialImageDataset(root_dir=os.path.join(adv_images_folder_path, subfolder), transform=transform)\n",
        "    list_of_datasets.append(dataset)\n",
        "\n",
        "combined_adv_dataset = ConcatDataset(list_of_datasets)\n",
        "adv_loader = DataLoader(combined_adv_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "M_sqh2qSINEB"
      },
      "id": "M_sqh2qSINEB",
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ASR - ile % ataków się udało\n",
        "Fooling rate - ile % ataków co zmyliło source zmyliło też target\n",
        "Same mistake - ile % to był ten sam błąd\n",
        "wszystko pod warunkiem że target poprawnie sklasyfikował oryginał\n",
        "\"\"\"\n",
        "\n",
        "#Ewaluation function will be added"
      ],
      "metadata": {
        "id": "zN43-cvXExVt"
      },
      "id": "zN43-cvXExVt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}