{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gosiuniunia/uczenie-glebokie/blob/main/attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2446fdd",
      "metadata": {
        "id": "f2446fdd"
      },
      "source": [
        "Źródła:\n",
        "\n",
        "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
        "\n",
        "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
        "\n",
        "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023.\n",
        "\n",
        "SU, Jiawei; VARGAS, Danilo Vasconcellos; SAKURAI, Kouichi. One pixel attack for fooling deep neural networks. IEEE Transactions on Evolutionary Computation, 2019, 23.5: 828-841.\n",
        "\n",
        "WONG, Eric; RICE, Leslie; KOLTER, J. Zico. Fast is better than free: Revisiting adversarial training. arXiv preprint arXiv:2001.03994, 2020.\n",
        "\n",
        "MOOSAVI-DEZFOOLI, Seyed-Mohsen; FAWZI, Alhussein; FROSSARD, Pascal. Deepfool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. p. 2574-2582.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZLw7AZ3ekD88",
        "outputId": "a02a3b3b-9f2e-4c2e-9c06-7325015c705c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZLw7AZ3ekD88",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchattacks\n",
        "!pip install sewar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmV4mnuJpq8A",
        "outputId": "33417867-a232-4daf-ba8f-24205da84370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hmV4mnuJpq8A",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (0.24.0+cu126)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.0.2)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->torchattacks) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.8.2->torchattacks) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.3)\n",
            "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, idna, chardet, requests, torchattacks\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "google-adk 1.19.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.29.1 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "pysal 25.7 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.66 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.52.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.12.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n",
            "Collecting sewar\n",
            "  Downloading sewar-0.4.6.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sewar) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sewar) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sewar) (11.3.0)\n",
            "Building wheels for collected packages: sewar\n",
            "  Building wheel for sewar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sewar: filename=sewar-0.4.6-py3-none-any.whl size=11418 sha256=15da91ab5a20a49ca4d804032a608936df570ef5cc3abdca91d2caa667d5d433\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/4e/29/b15a3d425c5f0fe8f461cbfdaf4fa98ef203fed97ce1df6695\n",
            "Successfully built sewar\n",
            "Installing collected packages: sewar\n",
            "Successfully installed sewar-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8708bca8",
      "metadata": {
        "id": "8708bca8",
        "outputId": "46280faf-ed1c-4cfa-a000-4cda9ea204af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b3d1c2c06d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import sewar\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
        "\n",
        "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
        "from torchattacks import PGD, FGSM, CW, AutoAttack, DeepFool, OnePixel\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3a884b19",
      "metadata": {
        "id": "3a884b19",
        "outputId": "5df795d1-f7ba-48e5-e215-cf10157572d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG and ResNet architecture"
      ],
      "metadata": {
        "id": "-l7ze4nMRrg5"
      },
      "id": "-l7ze4nMRrg5"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc0597d1",
      "metadata": {
        "collapsed": true,
        "id": "dc0597d1"
      },
      "outputs": [],
      "source": [
        "# VGG model architecture\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Blok 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256*4*4, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        # x = self.block5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b11b9050",
      "metadata": {
        "collapsed": true,
        "id": "b11b9050"
      },
      "outputs": [],
      "source": [
        "# ResNet18 model architecture\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main_path = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                      stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main_path(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
        "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
        "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
        "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack generation function"
      ],
      "metadata": {
        "id": "60GuQ88oRz2G"
      },
      "id": "60GuQ88oRz2G"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_images(source_model, dataset, mean, std, source_name, train=False, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generates adversarial images for all attacks in batches to avoid CUDA OOM.\n",
        "    \"\"\"\n",
        "    attack_configs = [\n",
        "        {\"name\": \"FGSM\", \"atk\": FGSM(source_model, eps=4/255)},\n",
        "        {\"name\": \"PGD\", \"atk\": PGD(source_model, eps=4/255, alpha=2/255, steps=20, random_start=True)},\n",
        "        {\"name\": \"CW\", \"atk\": CW(source_model, c=1, steps=300, lr=0.01)},\n",
        "        {\"name\": \"AutoAttack\", \"atk\": AutoAttack(source_model, norm=\"Linf\", eps=4/255)},\n",
        "        {\"name\": \"DeepFool\", \"atk\": DeepFool(source_model, steps=50, overshoot=0.02)},\n",
        "        {\"name\": \"OnePixel\", \"atk\": OnePixel(source_model, pixels=1, steps=50, popsize=20)}\n",
        "    ]\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for config in attack_configs:\n",
        "        attack_name = config[\"name\"]\n",
        "        atk = config[\"atk\"]\n",
        "        print(f\"Generating {attack_name} attacks\")\n",
        "\n",
        "        if attack_name == \"AutoAttack\":\n",
        "            atk.attacks_to_run = ['apgd-ce']\n",
        "\n",
        "        atk.set_normalization_used(mean, std)\n",
        "        adv_images_list = []\n",
        "        adv_labels_list = []\n",
        "\n",
        "        for batch_images, batch_labels in loader:\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            adv_batch = atk(batch_images, batch_labels)\n",
        "\n",
        "            adv_images_list.append(adv_batch.cpu())\n",
        "            adv_labels_list.append(batch_labels.cpu())\n",
        "\n",
        "            del batch_images, batch_labels, adv_batch\n",
        "\n",
        "        adv_images_all = torch.cat(adv_images_list)\n",
        "        adv_labels_all = torch.cat(adv_labels_list)\n",
        "\n",
        "        folder_prefix = \"train\" if train else \"test\"\n",
        "        save_images(adv_images_all, adv_labels_all, adv_images_folder_path, f\"{folder_prefix}_{source_name}_{attack_name}\")\n"
      ],
      "metadata": {
        "id": "URG21dM3lQyK"
      },
      "id": "URG21dM3lQyK",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial images saving and loading functions"
      ],
      "metadata": {
        "id": "lw050aiISDsV"
      },
      "id": "lw050aiISDsV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save images to the designated folder\n",
        "\n",
        "def save_images(images, labels, path, folder_name=None):\n",
        "  \"\"\"\n",
        "  This function saves given images with their labels in the given folder.\n",
        "  Subfolder can be specified. Each image is saved as adv_image_{index}_label_{labels[index]}.png,\n",
        "  \"\"\"\n",
        "  try:\n",
        "    path = os.path.join(path, folder_name)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  for i, (image_tensor, label) in enumerate(zip(images, labels)):\n",
        "    img = image_tensor.detach().permute(1,2,0).cpu().numpy()\n",
        "    img = (img * 255).clip(0,255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(img)\n",
        "\n",
        "    filename = f\"adv_image_{i}_label_{int(label)}.png\"\n",
        "    filepath = os.path.join(path, filename)\n",
        "    image_pil.save(filepath)"
      ],
      "metadata": {
        "id": "jAlQUFmRudGS"
      },
      "id": "jAlQUFmRudGS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all of the images in specified folder to torch dataset\n",
        "\n",
        "class AdversarialImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class loads the images from specified folder (save_images generated folder)\n",
        "    and transforms it to torch dataset for future learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "\n",
        "        for file in os.listdir(root_dir):\n",
        "            if file.endswith(\".png\"):\n",
        "                self.image_files.append(file)\n",
        "\n",
        "        self.image_files.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        label = int(img_name.split(\"_\")[-1].split(\".\")[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "DZjOmzanJq9y"
      },
      "id": "DZjOmzanJq9y",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "TN41LZjJSJus"
      },
      "id": "TN41LZjJSJus"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c936e98a",
      "metadata": {
        "id": "c936e98a"
      },
      "outputs": [],
      "source": [
        "# Attack efficiency metrics\n",
        "\n",
        "def attack_success_rate(labels, preds):\n",
        "    \"\"\"\n",
        "    Computes the Attack Success Rate (ASR).\n",
        "    Measures how many attacks succeeded.\n",
        "    \"\"\"\n",
        "    labels, preds = labels.to(device), preds.to(device)\n",
        "    total = len(labels)\n",
        "    succeeded = (preds != labels).sum().item()\n",
        "    return 100.0 * succeeded / total\n",
        "\n",
        "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the fooling rate for transfer attacks.\n",
        "\n",
        "    - source_pred: predictions of the SOURCE model on adversarial images\n",
        "    - target_pred: predictions of the TARGET model on adversarial images\n",
        "    - clean_target_pred: predictions of the TARGET model on clean images\n",
        "\n",
        "    We measure cases where:\n",
        "    1) the adversarial sample fools the SOURCE model,\n",
        "    2) it also fools the TARGET model,\n",
        "    3) but the TARGET classified the clean version correctly.\n",
        "\n",
        "    The fooling rate is: Q / P\n",
        "    where:\n",
        "        P = number of samples that fooled the source\n",
        "        Q = number of samples that fooled both models\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    fool_source = source_pred != labels\n",
        "    fool_target = target_pred != labels\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "\n",
        "    P = fool_source.sum().item()\n",
        "    Q = (fool_source & fool_target & correct_target_clean).sum().item()\n",
        "\n",
        "    return 100.0 * Q / P if P > 0 else 0.0\n",
        "\n",
        "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    \"\"\"\n",
        "    Computes the rate at which both the source and target models make\n",
        "    the SAME wrong prediction on adversarial samples.\n",
        "\n",
        "    We consider ONLY samples where:\n",
        "    - the target model classified the CLEAN image correctly\n",
        "    - the target model is fooled on the adversarial image\n",
        "\n",
        "    Among those, we measure how often:\n",
        "        source_pred == target_pred (same incorrect class)\n",
        "    \"\"\"\n",
        "    labels, source_pred, target_pred, clean_target_pred = labels.to(device), source_pred.to(device), target_pred.to(device), clean_target_pred.to(device)\n",
        "    correct_target_clean = clean_target_pred == labels\n",
        "    fool_target = target_pred != labels\n",
        "    same_mistake = source_pred == target_pred\n",
        "\n",
        "    mask = fool_target & correct_target_clean\n",
        "    denom = mask.sum().item()\n",
        "\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "\n",
        "    num = (mask & same_mistake).sum().item()\n",
        "    return 100.0 * num / denom\n",
        "\n",
        "# Perturbation quality metrics\n",
        "\n",
        "def ssim(images, adv_images):\n",
        "    \"\"\"\n",
        "    Computes the mean Structural Similarity Index (SSIM)\n",
        "    between original and adversarial images.\n",
        "\n",
        "    SSIM measures perceptual similarity considering:\n",
        "    - luminance\n",
        "    - contrast\n",
        "    - structure\n",
        "\n",
        "    SSIM = 1 means identical images.\n",
        "    Lower values indicate stronger or more visible perturbations.\n",
        "    \"\"\"\n",
        "    ssim_list = []\n",
        "\n",
        "    for i in range(images.size(0)):\n",
        "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy().astype(np.uint8)\n",
        "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
        "        ssim_list.append(ssim_val)\n",
        "\n",
        "    return float(np.mean(ssim_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack generation process\n",
        "The procedure is as follows:\n",
        "\n",
        "1. Attacks are generated on CIFAR10 test set using source model and then transferred to the target model.\n",
        "\n",
        "2. To do adversarial training we generate attacks on CIFAR10 train set and then use it to train the model on which were they generated.\n",
        "\n",
        "3. Attacks generated on the original models are used for evaluation. When calculating the metrics, we consider only those adversarial images which originals ware correctly classified by respected models."
      ],
      "metadata": {
        "id": "VXFIDJs6poP_"
      },
      "id": "VXFIDJs6poP_"
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_path = \"/content/drive/MyDrive/vgg_epoch_80.pth\"\n",
        "resnet_model_path = \"/content/drive/MyDrive/model_ResNet18_cifar10_20251112.pth\"\n",
        "adv_images_folder_path = \"/content/drive/MyDrive/adversarial_images\" # \"/content/drive/MyDrive/\" is mandatory"
      ],
      "metadata": {
        "id": "jmzyB7P2nE38"
      },
      "id": "jmzyB7P2nE38",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "beaef5c2",
      "metadata": {
        "id": "beaef5c2",
        "outputId": "00a13d42-d05e-4024-88f8-bc25cd1a84d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 90.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Original CIFAR10 Dataset\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG model\n",
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3YyqbGgGm0q",
        "outputId": "96628120-7f5c-41dc-efe5-0b163d699eb4"
      },
      "id": "r3YyqbGgGm0q",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (block5): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet model\n",
        "model_resnet = ResNet18(3, 10)\n",
        "model_resnet.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
        "model_resnet.to(device)\n",
        "model_resnet.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQHNzY7Gp4w",
        "outputId": "217a828a-0cbf-49e7-e6b6-8d0875c94e84"
      },
      "id": "gTQHNzY7Gp4w",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG -> Resnet\n",
        "source_model = model_vgg\n",
        "target_model = model_resnet\n",
        "dataset = testset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"VGG\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ouxTxJ-GPl",
        "outputId": "8c3ae73e-7b98-4d75-9fb3-0ffe7486aedf"
      },
      "id": "c4ouxTxJ-GPl",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet -> VGG\n",
        "source_model = model_resnet\n",
        "target_model = model_vgg\n",
        "dataset = testset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"ResNet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZWLgkevh0cJ",
        "outputId": "2afae706-6896-4c84-e85b-3a6887e1aab3"
      },
      "id": "WZWLgkevh0cJ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating FGSM attacks\n",
            "Generating PGD attacks\n",
            "Generating CW attacks\n",
            "Generating AutoAttack attacks\n",
            "Generating DeepFool attacks\n",
            "Generating OnePixel attacks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for VGG\n",
        "source_model = model_vgg\n",
        "dataset = trainset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"VGG\", train=True)"
      ],
      "metadata": {
        "id": "Jqp7ew8RFtUF"
      },
      "id": "Jqp7ew8RFtUF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial train set generation for ResNet\n",
        "source_model = model_resnet\n",
        "dataset = trainset\n",
        "generate_adversarial_images(source_model, dataset, mean, std, \"ResNet\", train=True)"
      ],
      "metadata": {
        "id": "EHlKSZhiGI5f"
      },
      "id": "EHlKSZhiGI5f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}