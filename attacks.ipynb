{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2446fdd",
      "metadata": {
        "id": "f2446fdd"
      },
      "source": [
        "Źródła:\n",
        "\n",
        "Gu, Jindong, et al. \"A survey on transferability of adversarial examples across deep neural networks.\" arXiv preprint arXiv:2310.17626 (2023).\n",
        "\n",
        "Podder, Rakesh, and Sudipto Ghosh. \"Impact of white-box adversarial attacks on convolutional neural networks.\" 2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC). IEEE, 2024.\n",
        "\n",
        "Qin, Yunxiao, et al. \"Training meta-surrogate model for transferable adversarial attack.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 37. No. 8. 2023."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZLw7AZ3ekD88",
        "outputId": "1353a960-ca77-4ca6-e89b-497cf6bf5826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZLw7AZ3ekD88",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8708bca8",
      "metadata": {
        "id": "8708bca8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3a884b19",
      "metadata": {
        "id": "3a884b19",
        "outputId": "4dffbb42-ea96-419f-b778-6c8b9a283fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_path = \"/content/drive/MyDrive/vgg_epoch_80.pth\"\n",
        "resnet_model_path = \"/content/drive/MyDrive/model_ResNet18_cifar10.pth\""
      ],
      "metadata": {
        "id": "jmzyB7P2nE38"
      },
      "id": "jmzyB7P2nE38",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "dc0597d1",
      "metadata": {
        "collapsed": true,
        "id": "dc0597d1",
        "outputId": "d825304d-9d38-456b-f2e9-44c773714665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (block5): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Preparing VGG model\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Blok 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256*4*4, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        # x = self.block5(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_vgg = VGG16(num_classes=10)\n",
        "model_vgg.load_state_dict(torch.load(vgg_model_path, map_location=device))\n",
        "model_vgg.to(device)\n",
        "model_vgg.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b11b9050",
      "metadata": {
        "collapsed": true,
        "id": "b11b9050",
        "outputId": "94c3eb81-6290-4a1e-e35e-83b31850980d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (main_path): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Preparing ResNet18 model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, input_channels, output_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main_path = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
        "                      stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or input_channels != output_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(output_channels)\n",
        "            )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.main_path(x) + self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3,\n",
        "                      stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1),\n",
        "            BasicBlock(input_channels=64, output_channels=64, stride=1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(input_channels=64, output_channels=128, stride=2),\n",
        "            BasicBlock(input_channels=128, output_channels=128, stride=1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(input_channels=128, output_channels=256, stride=2),\n",
        "            BasicBlock(input_channels=256, output_channels=256, stride=1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(input_channels=256, output_channels=512, stride=2),\n",
        "            BasicBlock(input_channels=512, output_channels=512, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model_resnet = ResNet18(3, 10)\n",
        "model_resnet.load_state_dict(torch.load(resnet_model_path, map_location=device))\n",
        "model_resnet.to(device)\n",
        "model_resnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "beaef5c2",
      "metadata": {
        "id": "beaef5c2"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3fe95a",
      "metadata": {
        "id": "8d3fe95a"
      },
      "outputs": [],
      "source": [
        "# Fast Gradient Sign Method (FGSM)\n",
        "\n",
        "def fgsm(model, image, label, epsilon=0.1):\n",
        "    image.requires_grad_(True)\n",
        "    output = model(image)\n",
        "    loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    perturbation = epsilon * torch.sign(image.grad)\n",
        "    adversarial_image = image + perturbation\n",
        "    return adversarial_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20adc1af",
      "metadata": {
        "id": "20adc1af"
      },
      "outputs": [],
      "source": [
        "# Projected Gradient Descent (PGD)\n",
        "\n",
        "def pgd(model, image, label, epsilon=0.03, alpha=0.05, num_iters=40):\n",
        "    original_image = image.clone()\n",
        "    adversarial_image = image.clone()\n",
        "\n",
        "    for _ in range(num_iters):\n",
        "        adversarial_image.requires_grad_(True)\n",
        "        output = model(adversarial_image)\n",
        "        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gradient = adversarial_image.grad.data\n",
        "            adversarial_image += alpha * gradient.sign()\n",
        "\n",
        "            perturbation = torch.clamp(adversarial_image - original_image, min=-epsilon, max=epsilon)\n",
        "            adversarial_image = torch.clamp(original_image + perturbation, 0, 1)\n",
        "\n",
        "        adversarial_image = adversarial_image.detach()\n",
        "\n",
        "    return adversarial_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f1b45321",
      "metadata": {
        "id": "f1b45321",
        "outputId": "f80fe445-0aad-40a6-bcd4-177dae81da3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM(model_name=VGG16, device=cuda:0, attack_mode=default, targeted=False, normalization_used=False, eps=0.03137254901960784)\n",
            "PGD(model_name=VGG16, device=cuda:0, attack_mode=default, targeted=False, normalization_used=False, eps=0.03137254901960784, alpha=0.008888888888888889, steps=10, random_start=True)\n",
            "CW(model_name=VGG16, device=cuda:0, attack_mode=default, targeted=False, normalization_used=False, c=0.1, kappa=0, steps=1000, lr=0.01)\n"
          ]
        }
      ],
      "source": [
        "# Adversarial attacks PyTorch: https://github.com/Harry24k/adversarial-attacks-pytorch/tree/master\n",
        "# Attacks are generated using the VGG model and then transfered to the ResNet\n",
        "from torchattacks import PGD, FGSM, CW\n",
        "\n",
        "# Default parameters values\n",
        "atk_fgsm = FGSM(model_vgg, eps=8/255)\n",
        "atk_pgd = PGD(model_vgg, eps=8/255, alpha=2/225, steps=10, random_start=True)\n",
        "atk_cw = CW(model_vgg, c=0.1, steps=1000, lr=0.01)\n",
        "print(atk_fgsm)\n",
        "print(atk_pgd)\n",
        "print(atk_cw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2a1d52c7",
      "metadata": {
        "id": "2a1d52c7",
        "outputId": "9d4ca1de-5270-45a8-a324-9d928bd10c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original batch size: 100\n",
            "Number of correctly classified examples: 86\n"
          ]
        }
      ],
      "source": [
        "# Samples generation using only correctly classified examples by vgg model\n",
        "import random\n",
        "\n",
        "def predict(model, images):\n",
        "    with torch.no_grad():\n",
        "        _, pred = model(images).max(1)\n",
        "    return pred\n",
        "\n",
        "n_examples = 100\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "indices = random.sample(range(len(testset)), n_examples)\n",
        "data_samples = [testset[i] for i in indices]\n",
        "\n",
        "images = torch.stack([x[0] for x in data_samples])\n",
        "labels = torch.tensor([x[1] for x in data_samples])\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "vgg_pred = predict(model_vgg, images)\n",
        "correct_mask = vgg_pred.eq(labels)\n",
        "images = images[correct_mask]\n",
        "labels = labels[correct_mask]\n",
        "\n",
        "print(f\"Original batch size: {n_examples}\")\n",
        "print(f\"Number of correctly classified examples: {images.size(0)}\")\n",
        "\n",
        "adv_images_fgsm = atk_fgsm(images, labels)\n",
        "adv_images_pgd = atk_pgd(images, labels)\n",
        "adv_images_cw = atk_cw(images, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "82123111",
      "metadata": {
        "id": "82123111"
      },
      "outputs": [],
      "source": [
        "vgg_pred_fgsm = predict(model_vgg, adv_images_fgsm)\n",
        "vgg_pred_pgd = predict(model_vgg, adv_images_pgd)\n",
        "vgg_pred_cw = predict(model_vgg, adv_images_cw)\n",
        "\n",
        "resnet_pred = predict(model_resnet, images)\n",
        "resnet_pred_fgsm = predict(model_resnet, adv_images_fgsm)\n",
        "resnet_pred_pgd = predict(model_resnet, adv_images_pgd)\n",
        "resnet_pred_cw = predict(model_resnet, adv_images_cw)\n",
        "\n",
        "# print(labels)\n",
        "# print(\"---------\")\n",
        "# print(vgg_pred_fgsm)\n",
        "# print(vgg_pred_pgd)\n",
        "# print(vgg_pred_cw)\n",
        "# print(\"-----------\")\n",
        "# print(resnet_pred)\n",
        "# print(resnet_pred_fgsm)\n",
        "# print(resnet_pred_pgd)\n",
        "# print(resnet_pred_cw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c936e98a",
      "metadata": {
        "id": "c936e98a"
      },
      "outputs": [],
      "source": [
        "# Attack efficiency metrics\n",
        "\n",
        "def accuracy(labels, preds):\n",
        "    total = len(labels)\n",
        "    correct = preds.eq(labels).sum().item()\n",
        "    test_acc = 100.*correct/total\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "def fooling_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    fool_source = source_pred != labels\n",
        "    fool_target = target_pred != labels\n",
        "    correct_target_pred = clean_target_pred == labels\n",
        "\n",
        "    P = fool_source.sum().item()\n",
        "    Q = (fool_source & fool_target & correct_target_pred).sum().item() # We count samples, which were correctly classified by target that fooled both models\n",
        "\n",
        "    fool_rate = Q / P if P > 0 else 0.0\n",
        "    return 100.*fool_rate\n",
        "\n",
        "def same_mistake_rate(labels, source_pred, target_pred, clean_target_pred):\n",
        "    correct_target_pred = (clean_target_pred == labels)\n",
        "    fool_target = (target_pred != labels)\n",
        "    same_mistake = (source_pred == target_pred)\n",
        "\n",
        "    rate = (fool_target & same_mistake & correct_target_pred).sum().item() / (fool_target & correct_target_pred).sum().item() # We count the samples that fooled the model the same way taking into consideration only correctly classified samples by target\n",
        "    return 100.*rate\n",
        "\n",
        "# Perturbation quality metrics\n",
        "import sewar\n",
        "\n",
        "def ssim(images, adv_images):  # Structural Similarity Index Metric (SSIM) measures perceptual similarity between two images, considering luminance, contrast, and structure.\n",
        "    ssim_list = []\n",
        "\n",
        "    for i in range(images.size(0)):\n",
        "        img_1 = images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "        img_2 = adv_images[i].permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "        img_1 = (img_1 * 255).clip(0, 255).astype(np.uint8)\n",
        "        img_2 = (img_2 * 255).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        ssim_val, _ = sewar.ssim(img_1, img_2)\n",
        "        ssim_list.append(ssim_val)\n",
        "\n",
        "    return float(np.mean(ssim_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "76a43977",
      "metadata": {
        "id": "76a43977",
        "outputId": "a6c77420-e051-400c-902b-8382245fc011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Attack Efficiency Metrics ===\n",
            "  Attack  VGG Accuracy  ResNet Accuracy (originally correct only)  \\\n",
            "0   FGSM     41.860465                                  59.756098   \n",
            "1    PGD     17.441860                                  57.317073   \n",
            "2     CW     23.255814                                  64.634146   \n",
            "\n",
            "   Fooling Rate (VGG -> ResNet)  Same Mistake Rate (VGG -> ResNet)  \n",
            "0                     50.000000                          39.393939  \n",
            "1                     46.478873                          62.857143  \n",
            "2                     43.939394                          55.172414  \n",
            "=== SSIM values ===\n",
            "SSIM for FGSM: 0.995593204650596\n",
            "SSIM for PDG: 0.9962869869045448\n",
            "SSIM for CW: 0.9998410297384764\n"
          ]
        }
      ],
      "source": [
        "# Metric values\n",
        "import pandas as pd\n",
        "\n",
        "correct_mask_resnet = resnet_pred.eq(labels)\n",
        "attack_metrics = {\n",
        "    \"Attack\": [\"FGSM\", \"PGD\", \"CW\"],\n",
        "    \"VGG Accuracy\": [\n",
        "        accuracy(labels, vgg_pred_fgsm),\n",
        "        accuracy(labels, vgg_pred_pgd),\n",
        "        accuracy(labels, vgg_pred_cw)\n",
        "    ],\n",
        "    \"ResNet Accuracy (originally correct only)\": [\n",
        "        accuracy(labels[correct_mask_resnet], resnet_pred_fgsm[correct_mask_resnet]),\n",
        "        accuracy(labels[correct_mask_resnet], resnet_pred_pgd[correct_mask_resnet]),\n",
        "        accuracy(labels[correct_mask_resnet], resnet_pred_cw[correct_mask_resnet])\n",
        "    ],\n",
        "    \"Fooling Rate (VGG -> ResNet)\": [\n",
        "        fooling_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
        "        fooling_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
        "        fooling_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
        "    ],\n",
        "    \"Same Mistake Rate (VGG -> ResNet)\": [\n",
        "        same_mistake_rate(labels, vgg_pred_fgsm, resnet_pred_fgsm, resnet_pred),\n",
        "        same_mistake_rate(labels, vgg_pred_pgd, resnet_pred_pgd, resnet_pred),\n",
        "        same_mistake_rate(labels, vgg_pred_cw, resnet_pred_cw, resnet_pred)\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_attack = pd.DataFrame(attack_metrics)\n",
        "print(\"=== Attack Efficiency Metrics ===\")\n",
        "print(df_attack)\n",
        "\n",
        "print(\"=== SSIM values ===\")\n",
        "print(\"SSIM for FGSM:\", ssim(images, adv_images_fgsm))\n",
        "print(\"SSIM for PDG:\", ssim(images, adv_images_pgd))\n",
        "print(\"SSIM for CW:\", ssim(images, adv_images_cw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ec60d37f",
      "metadata": {
        "id": "ec60d37f",
        "outputId": "399c09b8-1e95-4306-9ca3-a17549f9ce8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Wisualization of one sample for VGG prediction\n",
        "index = 1 # Index number must be lower than correctly classified examples\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
        "fig.suptitle(\"VGG\")\n",
        "axs[0].imshow((images[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[0].set_title(f\"Original: {labels[index]}\")\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow((adv_images_fgsm[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[1].set_title(f\"FGSM: {vgg_pred_fgsm[index]}\")\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow((adv_images_pgd[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[2].set_title(f\"FGSM: {vgg_pred_pgd[index]}\")\n",
        "axs[2].axis('off')\n",
        "\n",
        "axs[3].imshow((adv_images_cw[index].permute(1, 2, 0).cpu().detach().numpy()* 255).clip(0, 255).astype(np.uint8))\n",
        "axs[3].set_title(f\"FGSM: {vgg_pred_cw[index]}\")\n",
        "axs[3].axis('off')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}